{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev\n",
        "! pip install Pillow\n",
        "! pip install pytesseract\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' \n",
        "!python -m pip install torchvision tesseract\n",
        "!git clone https://github.com/facebookresearch/detectron2.git\n",
        "!python -m pip install -e detectron2\n",
        "!pip3 install labelbox[data]\n",
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "7FXGdOg5Bjid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IYaS9VeBgx2"
      },
      "outputs": [],
      "source": [
        "# model train and predict libraries\n",
        "from datasets import load_dataset \n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import ast\n",
        "from transformers import LayoutLMv2Processor\n",
        "from datasets import Features, Sequence, ClassLabel, Value, Array2D, Array3D\n",
        "from transformers import pipeline\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import LayoutLMv2ForTokenClassification, AdamW\n",
        "import torch\n",
        "from tqdm.notebook import tqdm # 순회 가능한 객체의 진행률을 progress bar로 표현해주고 남은 시간 정보 알려줌\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "total_text=[]\n",
        "total_location=[]\n",
        "total_lable=[]\n",
        "for h in range(1,66):\n",
        "  with open(\"/content/drive/MyDrive/클컴/train_data_image/train\"+str(h)+\".json\") as json_:\n",
        "    load_json = json.load(json_)\n",
        "\n",
        "\n",
        "  event=load_json\n",
        "  images=load_json['images'][0]\n",
        "  text=[]\n",
        "\n",
        "  location=[]\n",
        "  for i in event['images'][0]['fields']:\n",
        "    text.append(str(i['inferText']))\n",
        "    location.append([int(i['boundingPoly']['vertices'][0]['x']),int(i['boundingPoly']['vertices'][0]['y']),int(i['boundingPoly']['vertices'][1]['x']),int(i['boundingPoly']['vertices'][2]['y'])])\n",
        "\n",
        "  table_lable=[0 for _ in range(len(text))]\n",
        "  for i in range(len(table_lable)):\n",
        "    if i %2==0:\n",
        "      table_lable[i]=1\n",
        "  # layoutlmv2 모델의 특성에 따라서 이미지의 크기를 단일화 시켜주어야 한다.(1000,1000) 픽셀 단위로 계산되며 위치정보를 각각 전체 크기의 비율로 하여\n",
        "  # 위치를 조정한다.\n",
        "\n",
        "  embedding_loaction=[]\n",
        "\n",
        "  image = Image.open(\"/content/drive/MyDrive/클컴/train_data_image/train\"+str(h)+\".jpeg\")\n",
        "  image = image.convert(\"RGB\")\n",
        "\n",
        "  for j in range(len(location)):\n",
        "    temp=[]\n",
        "    \n",
        "    temp.append(int(location[j][0]/image.size[0]*1000))\n",
        "    temp.append(int(location[j][1]/image.size[1]*1000))\n",
        "    temp.append(int(location[j][2]/image.size[0]*1000))\n",
        "    temp.append(int(location[j][3]/image.size[1]*1000))\n",
        "    for z in range(len(temp)):\n",
        "      if temp[z]<0:\n",
        "        temp[z]=0\n",
        "    embedding_loaction.append(temp)\n",
        "  total_text.append(text)\n",
        "  total_location.append(embedding_loaction)\n",
        "  total_lable.append(table_lable)\n"
      ],
      "metadata": {
        "id": "_BFeQd9zBkUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_index=[]\n",
        "for i in range(len(total_location)):\n",
        "  for j in range(len(total_location[i])):\n",
        "    if (total_location[i][j][2]-total_location[i][j][0]) < 0 or (total_location[i][j][3]-total_location[i][j][1])< 0 :\n",
        "      remove_index.append(i)"
      ],
      "metadata": {
        "id": "NNw8ttoEBkWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tt=[i for i in range(1,66)]\n",
        "image_path=[\"train\"+str(i)+\".jpeg\" for i in range(1,66)]"
      ],
      "metadata": {
        "id": "52difnKBBkZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame(tt,columns=['id'])\n",
        "df['words']=total_text\n",
        "df['bboxes']=total_location\n",
        "df['ner_tags']=total_lable\n",
        "df['image_path']=image_path\n",
        "df=df.drop(remove_index,axis=0)"
      ],
      "metadata": {
        "id": "RSO67ZgVBkbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.to_csv('train_data.csv',index=False)"
      ],
      "metadata": {
        "id": "BfA-b0I6Bkdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('train_data.csv')"
      ],
      "metadata": {
        "id": "bIZ9_HeqBkgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install latest labelbox version (3.0 or above)\n",
        "# !pip3 install labelbox[data]\n",
        "\n",
        "import labelbox\n",
        "# Enter your Labelbox API key here\n",
        "LB_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjbGU5cDhnb2oxMWR3MDd1MjNjem5jdndoIiwib3JnYW5pemF0aW9uSWQiOiJjbGU5cDhnbzMxMWR2MDd1MjBrbGEweGc2IiwiYXBpS2V5SWQiOiJjbGZhYXNxeDcxbjRkMDd3bDJpaXUwc2ZlIiwic2VjcmV0IjoiNWRhZGZiYTU0YzEwODVkZjU5YWU4ODYwYzY5YzRiYmQiLCJpYXQiOjE2Nzg5MjE5ODAsImV4cCI6MjMxMDA3Mzk4MH0.7qbiis-IRQj-2jkJqBzjlCBH0bnAHdL0WXMfdb0jYfA\"\n",
        "# Create Labelbox client\n",
        "lb = labelbox.Client(api_key=LB_API_KEY)\n",
        "# Get project by ID\n",
        "project = lb.get_project('clfuz4j1o091g072x08641fpp')\n",
        "# Export image and text data as an annotation generator:\n",
        "labels = project.label_generator()\n",
        "\n",
        "# Export labels created in the selected date range as a json file:\n",
        "label_box = project.export_labels(download = True, start=\"2023-03-25\", end=\"2023-03-31\")"
      ],
      "metadata": {
        "id": "LHXXwtXbBt22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label box 기준으로 'ner_tags' 값을 변경시킨다.\n",
        "\n",
        "\n",
        "import ast\n",
        "box_loc=[ast.literal_eval(i) for i in train_df['bboxes']]\n",
        "image_path=[i for i in train_df['image_path']]\n",
        "tags=[]\n",
        "objects={}\n",
        "for i in image_path:\n",
        "  image_name=i\n",
        "  for j in range(len(label_box)):\n",
        "    if image_name == label_box[j]['External ID']:\n",
        "      temp_objects={}\n",
        "      for h in range(len(label_box[j]['Label']['objects'])):\n",
        "        temp_objects[label_box[j]['Label']['objects'][h]['value']]=label_box[j]['Label']['objects'][h]['bbox']\n",
        "      objects[image_name]=temp_objects\n",
        "\n",
        "labels = ['others','key','value','total','column_name','item','count','money']\n",
        "for i in range(len(box_loc)):\n",
        "  tags.append([ 0 for _ in range(len(box_loc[i]))])\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "for i in objects.keys():\n",
        "  image_size=Image.open(\"/content/drive/MyDrive/클컴/train_data_image/\"+str(i)).size\n",
        "  for j in objects[i].keys():\n",
        "    objects[i][j]=[objects[i][j]['left']/image_size[0]*1000,objects[i][j]['top']/image_size[1]*1000,(objects[i][j]['left']+objects[i][j]['width'])/image_size[0]*1000,(objects[i][j]['top']+objects[i][j]['height'])/image_size[1]*1000]\n",
        "\n",
        "import ast\n",
        "for i in range(len(box_loc)):\n",
        "  box_loc[i]=box_loc[i]\n",
        "import ast\n",
        "for i in range(len(box_loc)):\n",
        "  box_loc[i]=box_loc[i]\n",
        "\n",
        "for i in range(len(image_path)):\n",
        "  image_name=image_path[i]\n",
        "  for j in range(len(box_loc[i])):\n",
        "    #print(box_loc[i][j][0])\n",
        "    x1,x2,y1,y2=box_loc[i][j][0],box_loc[i][j][2],box_loc[i][j][1],box_loc[i][j][3]\n",
        "\n",
        "    for h in objects[image_name].keys():\n",
        "      if x1 >= objects[image_name][h][0]-10 and y1 >= objects[image_name][h][1]-10 and x2 <= objects[image_name][h][2]+10 and y2 <= objects[image_name][h][3]+10:\n",
        "        #print(tags[i][j],text[i][j])\n",
        "        tags[i][j]=labels.index(h)\n",
        "      \n",
        "#labels = ['others','customer','vendor','item']\n",
        "\n",
        "train_df['ner_tags']=tags\n",
        "train_df.to_csv('train_data.csv',index=False)\n"
      ],
      "metadata": {
        "id": "NRXMVJg6Bt5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oZsfi60oBt8F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}