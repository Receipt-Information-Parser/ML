{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP0I8fLsdE96ATuki5vnW+d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ao-MjT0gHFVX"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","! apt install tesseract-ocr\n","! apt install libtesseract-dev\n","! pip install Pillow\n","! pip install pytesseract\n","!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' \n","!python -m pip install torchvision tesseract\n","!git clone https://github.com/facebookresearch/detectron2.git\n","!python -m pip install -e detectron2\n","!pip3 install labelbox[data]\n","!pip install openai\n"],"metadata":{"id":"0NTPwQ9HHG6q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model train and predict libraries\n","from datasets import load_dataset \n","from PIL import Image, ImageDraw, ImageFont\n","import ast\n","from transformers import LayoutLMv2Processor\n","from datasets import Features, Sequence, ClassLabel, Value, Array2D, Array3D\n","from transformers import pipeline\n","from torch.utils.data import DataLoader\n","from transformers import LayoutLMv2ForTokenClassification, AdamW\n","import torch\n","from tqdm.notebook import tqdm # 순회 가능한 객체의 진행률을 progress bar로 표현해주고 남은 시간 정보 알려줌\n","import pandas as pd\n","\n"],"metadata":{"id":"cUQHTBKiHG89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset, filesystems, DatasetDict\n","\n","data = load_dataset(\"csv\", data_files='train_data.csv', split=\"train\")  # path to your file\n","\n","\n","# Split into 70% train, 30% test + validation\n","train_test_validation = data.train_test_split(test_size=0.2)\n","\n","# Split 30% test + validation into half test, half validation\n","test_validation = train_test_validation[\"test\"].train_test_split(test_size=0.5)\n","\n","# Gather the splits  to have a single DatasetDict\n","\n","dataset = DatasetDict(\n","    {\n","        \"train\": data,\n","        \"validation\": test_validation[\"train\"],\n","        \"test\": data[10],\n","    }\n",")\n","dataset['train'].save_to_disk('./train_data')"],"metadata":{"id":"KaUrooh-HG_C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 'LayoutLMv2Processor' 을 이용하여서 이전까지 전처리 했던 데이터를 이용하여 모델 학습에 맞는 형태로 전처리를 한번 더 해준다.\n","\n","from datasets import load_metric, load_from_disk,load_dataset,Features, Sequence, ClassLabel, Value, Array2D, Array3D\n","\n","\n","#labels=> 예측값의 layout 명칭\n","labels = ['others','key','value','total','column_name','item','count','money']\n","id2label = {v: k for v, k in enumerate(labels)}\n","label2id = {k: v for v, k in enumerate(labels)}\n","\n","#huggingface : https://huggingface.co/microsoft/layoutlmv2-base-uncased 의 pretrained 된 모델을 사용\n","#입력된 데이터를 모델에 학습을 시킬수 있는 데이터로 전환하는 전처리 하기 위한 모델이다.\n","\n","processor = LayoutLMv2Processor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\", revision=\"no_ocr\")\n","\n","\n","# 전처리 데이터의 데이터 타입을 지정 \n","features = Features({\n","    'image': Array3D(dtype=\"int64\", shape=(3, 224, 224)),\n","    'input_ids': Sequence(feature=Value(dtype='int64')),\n","    'attention_mask': Sequence(Value(dtype='int64')),\n","    'token_type_ids': Sequence(Value(dtype='int64')),\n","    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n","    'labels': Sequence(ClassLabel(names=labels)),\n","})\n","\n","def preprocess_data(example):\n","    processor.feature_extractor.apply_ocr=False\n","    images=[Image.open(\"/content/drive/MyDrive/클컴/train_data_image/\"+i).convert('RGB') for i in example['image_path']]\n","    words = [ast.literal_eval(i) for i in example['words']]\n","    boxes = [ast.literal_eval(i) for i in example['bboxes']]\n","    word_labels = [ast.literal_eval(i) for i in example['ner_tags']]\n","    encoded_inputs = processor(images, words, boxes=boxes, word_labels=word_labels,\n","                                 padding=\"max_length\", truncation=True)\n","    \n","    \n","    return encoded_inputs\n","dataset = load_from_disk('./train_data')\n","train_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset.column_names,features=features)\n","train_dataset.set_format(type = 'torch')\n"],"metadata":{"id":"-ak0tA3OHIbP"},"execution_count":null,"outputs":[]}]}